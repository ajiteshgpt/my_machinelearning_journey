{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-vdg_Q-fGRMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "EspP14FJIg3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/amazon.csv\")\n",
        "df.sample(5)"
      ],
      "metadata": {
        "id": "J28GRT74K5ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('Unnamed: 0', inplace=True,axis=1)\n",
        "df.dropna(subset=['reviewText'],inplace=True)"
      ],
      "metadata": {
        "id": "eEdOtEHbLAm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample()"
      ],
      "metadata": {
        "id": "Gkps5qi4LTFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "aq9fGKKFLUVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now have to maping the rating\n",
        "\n",
        "def maping (rating):\n",
        "  if rating<=2:\n",
        "    return 0\n",
        "  elif rating==3:\n",
        "    return 1\n",
        "  else:\n",
        "    return 2\n",
        "\n",
        "df[\"sentiments\"]=df['overall'].apply(maping)\n"
      ],
      "metadata": {
        "id": "I89CmBZELWGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(3)"
      ],
      "metadata": {
        "id": "vraDxJrXNkn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#class didtributions\n",
        "\n",
        "df[\"sentiments\"].value_counts().sort_index()"
      ],
      "metadata": {
        "id": "CkEi8b-VNtn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text processing\n",
        "\n",
        "stop_words=set(stopwords.words(\"english\"))\n",
        "lemmatizer=WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "KE1SgbiROJAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uWMN6mhwOcj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b892c384"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bec5fad1"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# funtion to clean raw data\n",
        "def processed_text(text):\n",
        "  text =str(text).lower() # will converts to lower case\n",
        "\n",
        "  text =re.sub(r'[^a-z\\s]',\"\",text) # remove non-alphabetic characters\n",
        "\n",
        "  #tokenization (splitting the text) and clean the data\n",
        "  words = text.split()\n",
        "\n",
        "  cleanWords=[lemmatizer.lemmatize(i) for i in words if i not in stop_words]\n",
        "  # lemmatizer.lematize(i) this converts a word into its base (dictionary) form.\n",
        "  # running --> run\n",
        "\n",
        "  #Stopwords are very common words that usually donâ€™t add much meaning.\n",
        "  # is , am , to ,  etc\n",
        "\n",
        "  return \" \".join(cleanWords)\n",
        "\n",
        "df['clean _text']=df[\"reviewText\"].apply(processed_text)"
      ],
      "metadata": {
        "id": "m-TJqtxbOxIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "gfN-gCFNP-SQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot A: Class Balance\n",
        "\n",
        "sns.countplot(x='sentiments', data=df)\n",
        "plt.title('Distribution of Sentiment Classes')\n",
        "plt.xticks([0, 1, 2])\n",
        "plt.xlabel('Sentiment Class')\n",
        "plt.ylabel('Count')"
      ],
      "metadata": {
        "id": "Abkl2mtmQfhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot B: Review Length Analysis\n",
        "# We calculate the number of words in each processed review\n",
        "df['review_length'] = df['clean _text'].apply(lambda x: len(x.split()))\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(data=df, x='review_length', hue='sentiments', kde=True)\n",
        "plt.title('Review Length Distribution by Class')\n",
        "plt.xlabel('Number of Words')\n",
        "plt.xlim(0, 200) # Limit x-axis to 200 words for better visibility\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "orD038isRGTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model training\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
      ],
      "metadata": {
        "id": "7DP-QdQsSX35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# train test split\n",
        "\n",
        "X=df['clean _text']\n",
        "y=df['sentiments']\n",
        "\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "cO3jiV2QRxfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pipe line flow\n",
        "\n",
        "\n",
        "# Step 1: TfidfVectorizer - Converts text to numerical vectors based on word importance.\n",
        "# Step 2: LogisticRegression - A linear classification model.\n",
        "#         We use 'multi_class=\"multinomial\"(used in Logistic Regression when the target variable has more than two classes)' to explicitly handle 3 classes.\n",
        "\n",
        "pipeline = Pipeline([\n",
        "\n",
        "                     ('tfidf', TfidfVectorizer(max_features=5000)),#Converts text documents into numerical vectors\n",
        "                     ('tf1',LogisticRegression(multi_class='multinomial', solver='saga', max_iter=1000))\n",
        "])"
      ],
      "metadata": {
        "id": "c6mLKutvSi6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.fit(X_train,y_train\n",
        "             )"
      ],
      "metadata": {
        "id": "X0lsnOzLT43Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred =pipeline.predict(X_test)"
      ],
      "metadata": {
        "id": "QSLGwaGSUJ_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, y_pred)\n"
      ],
      "metadata": {
        "id": "iGE13yEvUPi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Print Detailed Classification Report\n",
        "# Precision: Accuracy of positive predictions.\n",
        "# Recall: Ability to find all positive instances.\n",
        "# F1-Score: Harmonic mean of precision and recall.\n",
        "print(\"Classification Report\")\n",
        "target_names = ['Negative', 'Neutral', 'Positive']\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))"
      ],
      "metadata": {
        "id": "-5HfBpD4UUVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This shows where the model is getting confused (e.g., misclassifying Neutral as Positive)\n",
        "plt.figure(figsize=(8, 6))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a0KyWpPZUwsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text):\n",
        "\n",
        "    #Accepts a raw string, cleans it, and returns the predicted sentiment.\n",
        "\n",
        "    # The pipeline handles vectorization automatically\n",
        "    prediction_idx = pipeline.predict([text])[0]\n",
        "    probabilities = pipeline.predict_proba([text])[0]\n",
        "\n",
        "    labels = {0: 'Negative', 1: 'Neutral', 2: 'Positive'}\n",
        "    predicted_label = labels[prediction_idx]\n",
        "    confidence = probabilities[prediction_idx]\n",
        "\n",
        "    if confidence<0.90:\n",
        "      return f\"Input : {text}\\n Predicted sentiment : Negative (Confidance : {confidence})\"\n",
        "\n",
        "    elif confidence >0.90 and confidence<0.95 :\n",
        "      return f\"Input : {text}\\n Predicted sentiment : neutral (Confidance : {confidence})\"\n",
        "    else:\n",
        "        return f\"Input : {text}\\n Predicted sentiment : positive (Confidance : {confidence})\"\n"
      ],
      "metadata": {
        "id": "TA4qCXD0VJj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test cases\n",
        "\n",
        "print(predict_sentiment(\"i love this product but hate its design \"))"
      ],
      "metadata": {
        "id": "18E_FeKqV4u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "iurlpL4qV6K6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v1f-HlkrYq7W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}