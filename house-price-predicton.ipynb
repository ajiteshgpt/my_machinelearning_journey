{"cells":[{"cell_type":"code","source":["import pandas as pd\n","train = pd.read_csv('/content/test.csv')\n","test = pd.read_csv('/content/train.csv')"],"metadata":{"id":"bM6aMKSSscKF"},"id":"bM6aMKSSscKF","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# prompt: make a random forest prediction model with complete steps include , data collection , eda , data preprocessing , data visualization,, handeling missing values,encoding , scaling midel ytraining ets etc which is needed\n","\n","import pandas as pd\n","# Correcting the variable names as they seem swapped\n","train_df = pd.read_csv('/content/train.csv')\n","test_df = pd.read_csv('/content/test.csv')\n","\n","# --- Data Collection (Already done by reading the CSVs) ---\n","\n","# --- Exploratory Data Analysis (EDA) ---\n","print(\"Train Dataset Info:\")\n","train_df.info()\n","print(\"\\nTest Dataset Info:\")\n","test_df.info()\n","\n","print(\"\\nTrain Dataset Description:\")\n","print(train_df.describe())\n","print(\"\\nTest Dataset Description:\")\n","print(test_df.describe())\n","\n","print(\"\\nTrain Dataset Head:\")\n","print(train_df.head())\n","\n","# Check for missing values\n","print(\"\\nMissing values in Train Dataset:\")\n","print(train_df.isnull().sum())\n","print(\"\\nMissing values in Test Dataset:\")\n","print(test_df.isnull().sum())\n","\n","# --- Data Visualization (Example: distribution of a numerical column, if applicable) ---\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Example: Assuming there is a numerical column named 'Age' in the train data\n","if 'Age' in train_df.columns:\n","    plt.figure(figsize=(8, 5))\n","    sns.histplot(train_df['Age'].dropna(), kde=True)\n","    plt.title('Distribution of Age in Train Dataset')\n","    plt.xlabel('Age')\n","    plt.ylabel('Frequency')\n","    plt.show()\n","\n","# Example: Assuming there is a categorical column named 'Embarked' and a target 'Survived'\n","if 'Embarked' in train_df.columns and 'Survived' in train_df.columns:\n","    plt.figure(figsize=(8, 5))\n","    sns.countplot(x='Embarked', hue='Survived', data=train_df)\n","    plt.title('Survival Count by Embarked Port')\n","    plt.xlabel('Embarked Port')\n","    plt.ylabel('Count')\n","    plt.show()\n","\n","\n","# --- Handling Missing Values ---\n","# Example: Impute missing 'Age' with the mean\n","if 'Age' in train_df.columns:\n","    train_df['Age'].fillna(train_df['Age'].mean(), inplace=True)\n","    test_df['Age'].fillna(test_df['Age'].mean(), inplace=True)\n","\n","# Example: Impute missing 'Embarked' with the mode\n","if 'Embarked' in train_df.columns:\n","    train_df['Embarked'].fillna(train_df['Embarked'].mode()[0], inplace=True)\n","\n","# Example: Impute missing 'Fare' in test data with the mean (often needed in test but not train)\n","if 'Fare' in test_df.columns and test_df['Fare'].isnull().sum() > 0:\n","     test_df['Fare'].fillna(test_df['Fare'].mean(), inplace=True)\n","\n","\n","print(\"\\nMissing values after imputation in Train Dataset:\")\n","print(train_df.isnull().sum())\n","print(\"\\nMissing values after imputation in Test Dataset:\")\n","print(test_df.isnull().sum())\n","\n","\n","# --- Data Preprocessing and Feature Engineering (Examples) ---\n","# Example: Creating a new feature 'FamilySize'\n","if 'SibSp' in train_df.columns and 'Parch' in train_df.columns:\n","    train_df['FamilySize'] = train_df['SibSp'] + train_df['Parch'] + 1\n","    test_df['FamilySize'] = test_df['SibSp'] + test_df['Parch'] + 1\n","\n","# Example: Creating 'IsAlone' feature\n","if 'FamilySize' in train_df.columns:\n","    train_df['IsAlone'] = (train_df['FamilySize'] == 1).astype(int)\n","    test_df['IsAlone'] = (test_df['FamilySize'] == 1).astype(int)\n","\n","# Example: Extracting title from 'Name'\n","import re\n","def get_title(name):\n","    title_search = re.search(' ([A-Za-z]+)\\.', name)\n","    if title_search:\n","        return title_search.group(1)\n","    return \"\"\n","\n","if 'Name' in train_df.columns:\n","    train_df['Title'] = train_df['Name'].apply(get_title)\n","    test_df['Title'] = test_df['Name'].apply(get_title)\n","\n","    # Consolidate rare titles\n","    train_df['Title'] = train_df['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n","    train_df['Title'] = train_df['Title'].replace('Mlle', 'Miss')\n","    train_df['Title'] = train_df['Title'].replace('Ms', 'Miss')\n","    train_df['Title'] = train_df['Title'].replace('Mme', 'Mrs')\n","\n","    test_df['Title'] = test_df['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n","    test_df['Title'] = test_df['Title'].replace('Mlle', 'Miss')\n","    test_df['Title'] = test_df['Title'].replace('Ms', 'Miss')\n","    test_df['Title'] = test_df['Title'].replace('Mme', 'Mrs')\n","\n","\n","# --- Encoding Categorical Variables ---\n","# Example: One-Hot Encoding 'Embarked' and 'Title'\n","categorical_cols = ['Embarked', 'Title']\n","train_df = pd.get_dummies(train_df, columns=categorical_cols, drop_first=True)\n","test_df = pd.get_dummies(test_df, columns=categorical_cols, drop_first=True)\n","\n","# Align columns between train and test sets - important after one-hot encoding\n","train_cols = set(train_df.columns)\n","test_cols = set(test_df.columns)\n","\n","missing_in_test = list(train_cols - test_cols)\n","for c in missing_in_test:\n","    test_df[c] = 0\n","\n","missing_in_train = list(test_cols - train_cols)\n","for c in missing_in_train:\n","    train_df[c] = 0\n","\n","# Ensure the order of columns is the same\n","test_df = test_df[train_df.columns]\n","\n","\n","# --- Feature Selection (Example: Drop irrelevant columns) ---\n","# Drop columns that are not needed for the model\n","columns_to_drop = ['PassengerId', 'Name', 'Ticket', 'Cabin'] # Cabin often has too many missing values\n","train_df = train_df.drop(columns=columns_to_drop, errors='ignore')\n","test_df = test_df.drop(columns=columns_to_drop, errors='ignore')\n","\n","# Ensure target variable is not in features for test set\n","if 'Survived' in test_df.columns:\n","    test_df = test_df.drop('Survived', axis=1)\n","\n","\n","# Separate features and target variable\n","if 'Survived' in train_df.columns:\n","    X_train = train_df.drop('Survived', axis=1)\n","    y_train = train_df['Survived']\n","    X_test = test_df # Assuming the test set does not have the target\n","else:\n","    print(\"Target variable 'Survived' not found in the training data.\")\n","    # Adjust the following steps or add a placeholder for y_train if necessary\n","\n","# --- Scaling Numerical Features ---\n","from sklearn.preprocessing import StandardScaler\n","\n","# Identify numerical columns (exclude the target and one-hot encoded columns)\n","numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n","# Exclude one-hot encoded columns, which are typically binary (0 or 1)\n","numerical_cols_to_scale = [col for col in numerical_cols if not col.startswith(('Embarked_', 'Title_')) and col not in ['IsAlone']]\n","\n","scaler = StandardScaler()\n","X_train[numerical_cols_to_scale] = scaler.fit_transform(X_train[numerical_cols_to_scale])\n","X_test[numerical_cols_to_scale] = scaler.transform(X_test[numerical_cols_to_scale])\n","\n","\n","# --- Model Training: Random Forest ---\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Split training data for validation (optional but good practice)\n","X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n","\n","# Initialize and train the Random Forest model\n","# Using default parameters, tune as needed\n","model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced') # added class_weight for potentially imbalanced data\n","\n","model.fit(X_train_split, y_train_split)\n","\n","# --- Model Evaluation on Validation Set ---\n","y_val_pred = model.predict(X_val_split)\n","\n","print(\"\\nModel Evaluation on Validation Set:\")\n","print(\"Accuracy:\", accuracy_score(y_val_split, y_val_pred))\n","print(\"\\nClassification Report:\\n\", classification_report(y_val_split, y_val_pred))\n","print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_val_split, y_val_pred))\n","\n","# Optional: Cross-validation on the full training data\n","# print(\"\\nCross-validation scores (Accuracy):\")\n","# cv_scores = cross_val_score(model, X_train, y_train, cv=5) # 5-fold cross-validation\n","# print(cv_scores)\n","# print(\"Mean CV Accuracy:\", cv_scores.mean())\n","\n","\n","# --- Prediction on the Test Set ---\n","predictions = model.predict(X_test)\n","\n","# You can now use these predictions, e.g., for submission to a competition\n","# For example, if you need to create a submission file:\n","# test_passenger_ids = pd.read_csv('/content/test.csv')['PassengerId'] # Need original test IDs\n","# submission_df = pd.DataFrame({'PassengerId': test_passenger_ids, 'Survived': predictions})\n","# submission_df.to_csv('submission.csv', index=False)\n","# print(\"\\nPredictions made on the test set. Example first 10 predictions:\")\n","# print(predictions[:10])\n"],"metadata":{"id":"BOWRsfbesdhe"},"id":"BOWRsfbesdhe","execution_count":null,"outputs":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":868283,"sourceId":5407,"sourceType":"competition"},{"datasetId":7189589,"sourceId":11472168,"sourceType":"datasetVersion"}],"dockerImageVersionId":31040,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"papermill":{"default_parameters":{},"duration":217.97539,"end_time":"2025-06-29T09:09:53.657451","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-06-29T09:06:15.682061","version":"2.6.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}